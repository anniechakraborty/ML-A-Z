{"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Data.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n","\n","['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n","Missing data in each column:\n","Country      0\n","Age          1\n","Salary       1\n","Purchased    0\n","dtype: int64\n","\n","   Country    Age  Salary  Purchased\n","0    False  False   False      False\n","1    False  False   False      False\n","2    False  False   False      False\n","3    False  False   False      False\n","4    False  False    True      False\n","5    False  False   False      False\n","6    False   True   False      False\n","7    False  False   False      False\n","8    False  False   False      False\n","9    False  False   False      False\n"]}],"source":["print(X)\n","print()\n","print(y)\n","\n","print(\"Missing data in each column:\")\n","missing_data = dataset.isnull().sum()\n","print(missing_data)\n","\n","print()\n","print(dataset.isnull())"]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"markdown","metadata":{},"source":["Note : Our goal is to take care of the missing values in the dataset. One of the ways is by replacing them  with the average value of the column. Here we use the SimpleImputer class in the impute module of the sklearn package. We create an object of the class SimpleImputer and call it imputer. To the constructor, we pass the first paramter 'missing_values' and set it to np.nan which is a numpy property to handle the NULL values. And the second paramter passed is 'strategy' with value 'mean' indicating that the missing values will be replaced by the mean. "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n","imputer.fit(X[:, 1:3])\n","X[:, 1:3] = imputer.transform(X[:, 1:3])"]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"markdown","metadata":{},"source":["To encode categorical data, or columns with string data, we use one hot encoding instead of assigning the categories numbers because that leads to some unwanted numerical correleations for the model. One hot encoding splits the column into multiple columns for each category and uses binary vectors to do the encoding."]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before encoding:\n","[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n","\n","After encoding:\n","[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","print('Before encoding:')\n","print(X)\n","print()\n","X = np.array(ct.fit_transform(X))\n","print('After encoding:')\n","print(X)"]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoding the Dependent Variable: ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n","After encoding:\n","[0 1 0 0 1 1 0 1 0 1]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","print('Encoding the Dependent Variable:', y)\n","y = le.fit_transform(y)\n","\n","print('After encoding:')\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOihYlX/ooG5h+qw0sLIjn8","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
